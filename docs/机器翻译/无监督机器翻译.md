## 1 什么是无监督机器翻译？
无监督机器翻译(Unsupervised machine translation,UMT)是机器翻译的一种，在没有给定大规模双语平行语料的情况下，通过机器学习算法自动实现从一种自然语言到另一种自然语言的翻译。由于无监督机器翻译的方法避免了翻译模型对大规模平行语料的过度依赖，更适合低资源语言或领域


## 2 无监督机器翻译的发展
无监督神经机器翻译从 2017 年（Facebook提出）首次被实现至今，已经取得了很大的进步。其发展历程大约经历3个阶段：
- 第一个阶段为2017年Artetxe等人和Conneau等人分别使用无监督的方法实现跨语言词嵌入，再根据所学习到的映射矩阵获取词表，随后通过语言模型训练和反向翻译两项技术实现了无监督神经机器翻译。
- 第二阶段为Lample归纳的无监督神经机器翻译的三大原则，同时共享双语词汇表联合学习双语词嵌入，并通过BPE 编码将词表从单词转换为子词。
- 第三个阶段为无监督跨语言预训练模型的提出，成功将预训练模型应用到了无监督神经机器翻译任务上，大幅度刷新了无监督神经机器翻译的性能。
- 研究者们在这三个阶段的发展基础上提出了自己对无监督神经机器翻译模型的改进，如Yang等人在2019年提出的将共享编码器改为独立编码器以强化句子本身的语言特征；Ji等人在2020年使用词典完成的不同语系的无监督神经机器翻译。

## 3 基本实现方法
![无监督机器翻译](https://pic4.zhimg.com/80/v2-9bc3691853c1fb94718dc043fb9977ef_720w.webp)
- 初始化双语词表词向量。
    - 使用Word2vec单独训练两种语言的词向量，再通过学习一个变换矩阵将两种语言的词向量映射到同一个潜在空间。这样就可以获得一个精确度良好的双语词表。
    - 使用单词的字节对编码(BPE:Byte Pair Encoding)作为子字单元。这样做的好处是在减少了词表大小的同时，清除了翻译过程中出现“未知(UNK)”的问题。
    - 相比于第一种方法，第二种方法选择将两种单语语料混合打乱后共同学习词向量特征，源语言和目标语言可共享同一个词表。但是这样的跨语言词嵌入有个前提，即两种语言是同一语系中的相似语言。
- 语言建模
- 贴袋=迭代翻译

如果一个自动编码器被调教成完全按照输入的方式重建输入，那么它可能什么都做不了。在这种情况下，输出将得到完美的重建，但是在瓶颈层中没有任何有用的特性。为了解决这一问题，使用了降噪自动编码器。首先，实际输入因为增加了一些噪声而受到轻微干扰。
## 4 无监督机器翻译面临的挑战
- 目前无监督机器翻译的研究工作多基于英、法、德等同源语言。由于在非同源语言之间， 例如中英、英日等，学习到的词向量质量较低，无监督神经机器翻译在这些语言对上获得的性能较差。
- 目前无监督机器翻译的研究工作多假设测试集的领域与训练集领域类似，存在一定的局限性。除了测试集与训练集的领域可能不一致外，无监督翻译使用的源端和目标端单语语料还可能存在着领域不一致和数量规模不一致等问题，使得无监督神经机器翻译领域自适应问题变得更具挑战性。
- 