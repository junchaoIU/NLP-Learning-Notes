## 1 什么是无监督机器翻译？
无监督机器翻译(Unsupervised machine translation,UMT)是机器翻译的一种，在没有给定大规模双语平行语料的情况下，通过机器学习算法自动实现从一种自然语言到另一种自然语言的翻译。由于无监督机器翻译的方法避免了翻译模型对大规模平行语料的过度依赖，更适合低资源语言或领域


## 2 无监督机器翻译的发展
无监督神经机器翻译从 2017 年（Facebook提出）首次被实现至今，已经取得了很大的进步。其发展历程大约经历3个阶段：
- 第一个阶段为2017年Artetxe等人和Conneau等人分别使用无监督的方法实现跨语言词嵌入，再根据所学习到的映射矩阵获取词表，随后通过语言模型训练和反向翻译两项技术实现了无监督神经机器翻译。
- 第二阶段为Lample归纳的无监督神经机器翻译的三大原则，同时共享双语词汇表联合学习双语词嵌入，并通过BPE 编码将词表从单词转换为子词。
- 第三个阶段为无监督跨语言预训练模型的提出，成功将预训练模型应用到了无监督神经机器翻译任务上，大幅度刷新了无监督神经机器翻译的性能。
- 研究者们在这三个阶段的发展基础上提出了自己对无监督神经机器翻译模型的改进，如Yang等人在2019年提出的将共享编码器改为独立编码器以强化句子本身的语言特征；Ji等人在2020年使用词典完成的不同语系的无监督神经机器翻译。

## 3 经典论文基本实现方法
1. WORD TRANSLATION WITHOUT PARALLEL DATA (Alexis Conneau,2018,ICLR)
![](./image/word%20MT.png)
基于字典的方法。
- 首先将源语言和目标语言训练成词向量映射到一个巨大的向量空间中；
- 加入对抗训练（GAN），初始化源语言和目标语言的向量对齐，映射函数（旋转矩阵）为W
- 选取高质量的近邻词作为锚点，对W进行微调，提升源语言和目标语言字典的对齐质量

2. UNSUPERVISED MACHINE TRANSLATION USING MONOLINGUAL CORPORA ONLY (Guillaume Lample,2018,ICLR)
![](./image//USMT.jpg)
基于模型构建的方法
- 利用一个encoder-decoder思维。encoder可以把一种语言编码转换成一种通用表示，decoder则可以把通用表示还原成任意一种语言。
- 如果一个自动编码器被调教成完全按照输入的方式重建输入，那么它可能什么都做不了。所以在训练过程中不断加入噪音，来训练其（1）从加噪音的源句中还原源句的能力；（2）从加噪音的译文中还原源句的能力。
![](./image//UTMT.jpg)

3. Phrase-Based & Neural Unsupervised Machine Translation（Guillaume Lample, 2018）
![PBNUMT](./image//PBNUMT.png)
基于机器翻译模型，总结了前两篇论文的方法：
- 首先，他们使用推断的双语词典仔细初始化 MT 系统。
- 其次，他们通过训练序列到序列系统 (Sutskever et al., 2014; Bahdanau et al., 2015) 作为去噪自动编码器 (Vincent et al., 2008) 来利用强大的语言模型。
- 第三，他们通过反向翻译自动生成句子对，将无监督问题转变为有监督问题（Sennrich 等人，2015a），即将源到目标模型应用于源语句以生成用于训练目标到源模型，反之亦然。 
- 最后，它们限制编码器产生的潜在表示在两种语言之间共享。
![无监督机器翻译](https://pic4.zhimg.com/80/v2-9bc3691853c1fb94718dc043fb9977ef_720w.webp)
- 初始化双语词表词向量。
    - 使用Word2vec单独训练两种语言的词向量，再通过学习一个变换矩阵将两种语言的词向量映射到同一个潜在空间。这样就可以获得一个精确度良好的双语词表。
    - 使用单词的字节对编码(BPE:Byte Pair Encoding)作为子字单元。这样做的好处是在减少了词表大小的同时，清除了翻译过程中出现“未知(UNK)”的问题。
    - 相比于第一种方法，第二种方法选择将两种单语语料混合打乱后共同学习词向量特征，源语言和目标语言可共享同一个词表。但是这样的跨语言词嵌入有个前提，即两种语言是同一语系中的相似语言。
- 语言建模
- 迭代翻译

## 4 预训练-无监督机器翻译
Cross-lingual Language Model Pretraining
Unsupervised Neural Machine Translation with SMT as Posterior Regularization


## 4 无监督机器翻译面临的挑战
- 目前无监督机器翻译的研究工作多基于英、法、德等同源语言。由于在非同源语言之间， 例如中英、英日等，学习到的词向量质量较低，无监督神经机器翻译在这些语言对上获得的性能较差。
- 目前无监督机器翻译的研究工作多假设测试集的领域与训练集领域类似，存在一定的局限性。除了测试集与训练集的领域可能不一致外，无监督翻译使用的源端和目标端单语语料还可能存在着领域不一致和数量规模不一致等问题，使得无监督神经机器翻译领域自适应问题变得更具挑战性。