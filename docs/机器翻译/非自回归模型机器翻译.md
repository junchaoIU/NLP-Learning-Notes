## 什么是非自回归机器翻译（NAT）？
- 目前主流的神经机器翻译模型为自回归模型， 每一步的译文单词的生成都依赖于之前的翻译结果 ，因此模型只能逐词生成译文，翻译速度较慢 。
- Gu等人提出的非自回归神经机器翻译模型(NAT)对目标词的生成进行独立的建模，因此能够并行解码出整句译文，显著提升了模型的翻译速度。
![NAT](./image/NAT.jpg)

缺点：
- 非自回归模型在翻译质量上与自回归模型有较大差距，主要表现为模型在长句上的翻译效果较差，译文中通常包含较多的重复词和漏译错误。
- Gu等人指出，在给定原文时，目标端参考译文的概率分布具有“多峰性”，即一句原文可能对应多句意思相近的译文。由于无法进行teacher forcing训练，译文的“多峰性”会对模型的训练造成很大干扰。

优化方法：
- 要提升非自回归模型的翻译质量，最简单有效的方法是进行序列级的知识蒸馏。知识蒸馏能降低目标端文本的“复杂度”，从而降低模型的学习难度。
- 提升非自回归模型翻译质量的方法可以大体上分为三类：引入隐变量、改进训练目标和迭代式解码。



参考
- Gu, J., Bradbury, J., Xiong, C., Li, V. O., & Socher, R. (2017). Non-autoregressive neural machine translation. arXiv preprint arXiv:1711.02281.