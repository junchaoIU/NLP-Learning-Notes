
📚 NLP-Learning-Notes
-----
本书最新网址 https://junchaoiu.github.io/NLP-Learning-Notes ，欢迎大家访问 ～

NLP笔记，入门概念，基础知识，研究方法，顶会研读

作者研究导向：
- 机器翻译
- 知识图谱
-----
## 🌈 为什么写这份笔记

科研于我是一段孤独的道路

路上总会遇到很多很多人

希望我也有能力可以拉你一把

希望你也愿意和我一起走过一段路程

-----
## ✨导航
- 知识图谱技术
    - [知识图谱概述](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/知识图谱技术/知识图谱概述/知识图谱概述.md)
    - [知识表示](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/知识图谱技术/知识表示/知识表示.md)
    - [知识建模](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/知识图谱技术/知识建模/知识建模.md)
    - [知识抽取](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/知识图谱技术/知识抽取/知识抽取.md)
    - [知识融合](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/知识图谱技术/知识融合/知识融合.md)
    - [知识表示学习](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/知识图谱技术/知识表示学习/知识表示学习.md)
    - [知识存储](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/知识图谱技术/知识存储/知识存储.md)
    - [知识推理](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/知识图谱技术/知识推理/知识推理.md)
    - [多模态知识图谱概述](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/知识图谱技术/多模态知识图谱概述/多模态知识图谱概述.md)

- 机器翻译
    - [无监督机器翻译](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/机器翻译/无监督机器翻译.md)
        - [Word Translation Without Parallel Data (Alexis Conneau, ICLR, 2018)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#word-translation-without-parallel-data-alexis-conneau2018iclr)
        - [Unsupervised Machine Translation Using Monolingual Corpora Only (Guillaume Lample, ICLR, 2018)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#unsupervised-machine-translation-using-monolingual-corpora-only-guillaume-lample2018iclr)
        - [Phrase-Based & Neural Unsupervised Machine Translation (Guillaume Lample, EMNLP, 2018)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#phrase-based--neural-unsupervised-machine-translationguillaume-lample-emnlp-2018)
        - [Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data (Wei-Jen Ko, ACL, 2021)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#adapting-high-resource-nmt-models-to-translate-low-resource-related-languages-without-parallel-data)
        - [A Retrieve-and-Rewrite Initialization Method for Unsupervised Machine Translation (Shuo Ren, ACL, 2020)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#a-retrieve-and-rewrite-initialization-method-for-unsupervised-machine-translation)
        - [Multilingual Unsupervised Neural Machine Translation with Denoising Adapters (Ahmet Üstün, EMNLP, 2021)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#multilingual-unsupervised-neural-machine-translation-with-denoising-adapters)
        - [Reusing a Pretrained Language Model on Languages with Limited Corpora for Unsupervised NMT (Alexandra, EMNLP, 2020)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#reusing-a-pretrained-language-model-on-languages-with-limited-corpora-for-unsupervised-nmt-alexandra-emnlp-2020)

    - [机器翻译预训练模型](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/机器翻译/机器翻译预训练模型.md)
        - [Multilingual Denoising Pre-training for Neural Machine Translation (Yinhan Liu, Transactions of the Association for Computational Linguistics, 2022)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.md) 


- 未分类
    - [Attention is All You Need (Vaswani, NIPS, 2017)]()

- 模型压缩
    - [TinyBERT: Distilling BERT for Natural Language Understanding (Xiaoqi Jiao, EMNLP, 2020)]()

-----
## 🍉 欢迎批评指正 
由于个人水平有限，笔记中难免有笔误甚至概念错误之处，请各位不吝赐教，在issue中提出来。

-----
## 🌸 关于作者
[WU, JUNCHAO](https://github.com/junchaoIU)

[个人学术主页](https://junchaoiu.github.io/)

[个人博客-春天与爱情の樱花🌸](https://www.wujunchao.top/)

如遇到问题，请致邮（Email）：wujunchaoIU@outlook.com