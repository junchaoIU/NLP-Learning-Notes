
ğŸ“š NLP-Learning-Notes
-----
æœ¬ä¹¦æœ€æ–°ç½‘å€ https://junchaoiu.github.io/NLP-Learning-Notes ï¼Œæ¬¢è¿å¤§å®¶è®¿é—® ï½

NLPç¬”è®°ï¼Œå…¥é—¨æ¦‚å¿µï¼ŒåŸºç¡€çŸ¥è¯†ï¼Œç ”ç©¶æ–¹æ³•ï¼Œé¡¶ä¼šç ”è¯»

ä½œè€…ç ”ç©¶å¯¼å‘ï¼š
- æœºå™¨ç¿»è¯‘
- çŸ¥è¯†å›¾è°±
-----
## ğŸŒˆ ä¸ºä»€ä¹ˆå†™è¿™ä»½ç¬”è®°

ç§‘ç ”äºæˆ‘æ˜¯ä¸€æ®µå­¤ç‹¬çš„é“è·¯

è·¯ä¸Šæ€»ä¼šé‡åˆ°å¾ˆå¤šå¾ˆå¤šäºº

å¸Œæœ›æˆ‘ä¹Ÿæœ‰èƒ½åŠ›å¯ä»¥æ‹‰ä½ ä¸€æŠŠ

å¸Œæœ›ä½ ä¹Ÿæ„¿æ„å’Œæˆ‘ä¸€èµ·èµ°è¿‡ä¸€æ®µè·¯ç¨‹

-----
## âœ¨å¯¼èˆª
- çŸ¥è¯†å›¾è°±æŠ€æœ¯
    - [çŸ¥è¯†å›¾è°±æ¦‚è¿°](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/çŸ¥è¯†å›¾è°±æŠ€æœ¯/çŸ¥è¯†å›¾è°±æ¦‚è¿°/çŸ¥è¯†å›¾è°±æ¦‚è¿°.md)
    - [çŸ¥è¯†è¡¨ç¤º](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/çŸ¥è¯†å›¾è°±æŠ€æœ¯/çŸ¥è¯†è¡¨ç¤º/çŸ¥è¯†è¡¨ç¤º.md)
    - [çŸ¥è¯†å»ºæ¨¡](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/çŸ¥è¯†å›¾è°±æŠ€æœ¯/çŸ¥è¯†å»ºæ¨¡/çŸ¥è¯†å»ºæ¨¡.md)
    - [çŸ¥è¯†æŠ½å–](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/çŸ¥è¯†å›¾è°±æŠ€æœ¯/çŸ¥è¯†æŠ½å–/çŸ¥è¯†æŠ½å–.md)
    - [çŸ¥è¯†èåˆ](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/çŸ¥è¯†å›¾è°±æŠ€æœ¯/çŸ¥è¯†èåˆ/çŸ¥è¯†èåˆ.md)
    - [çŸ¥è¯†è¡¨ç¤ºå­¦ä¹ ](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/çŸ¥è¯†å›¾è°±æŠ€æœ¯/çŸ¥è¯†è¡¨ç¤ºå­¦ä¹ /çŸ¥è¯†è¡¨ç¤ºå­¦ä¹ .md)
    - [çŸ¥è¯†å­˜å‚¨](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/çŸ¥è¯†å›¾è°±æŠ€æœ¯/çŸ¥è¯†å­˜å‚¨/çŸ¥è¯†å­˜å‚¨.md)
    - [çŸ¥è¯†æ¨ç†](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/çŸ¥è¯†å›¾è°±æŠ€æœ¯/çŸ¥è¯†æ¨ç†/çŸ¥è¯†æ¨ç†.md)
    - [å¤šæ¨¡æ€çŸ¥è¯†å›¾è°±æ¦‚è¿°](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/çŸ¥è¯†å›¾è°±æŠ€æœ¯/å¤šæ¨¡æ€çŸ¥è¯†å›¾è°±æ¦‚è¿°/å¤šæ¨¡æ€çŸ¥è¯†å›¾è°±æ¦‚è¿°.md)

- æœºå™¨ç¿»è¯‘
    - [æ— ç›‘ç£æœºå™¨ç¿»è¯‘](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/æœºå™¨ç¿»è¯‘/æ— ç›‘ç£æœºå™¨ç¿»è¯‘.md)
        - [Word Translation Without Parallel Data (Alexis Conneau, ICLR, 2018)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#word-translation-without-parallel-data-alexis-conneau2018iclr)
        - [Unsupervised Machine Translation Using Monolingual Corpora Only (Guillaume Lample, ICLR, 2018)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#unsupervised-machine-translation-using-monolingual-corpora-only-guillaume-lample2018iclr)
        - [Phrase-Based & Neural Unsupervised Machine Translation (Guillaume Lample, EMNLP, 2018)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#phrase-based--neural-unsupervised-machine-translationguillaume-lample-emnlp-2018)
        - [Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data (Wei-Jen Ko, ACL, 2021)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#adapting-high-resource-nmt-models-to-translate-low-resource-related-languages-without-parallel-data)
        - [A Retrieve-and-Rewrite Initialization Method for Unsupervised Machine Translation (Shuo Ren, ACL, 2020)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#a-retrieve-and-rewrite-initialization-method-for-unsupervised-machine-translation)
        - [Multilingual Unsupervised Neural Machine Translation with Denoising Adapters (Ahmet ÃœstÃ¼n, EMNLP, 2021)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#multilingual-unsupervised-neural-machine-translation-with-denoising-adapters)
        - [Reusing a Pretrained Language Model on Languages with Limited Corpora for Unsupervised NMT (Alexandra, EMNLP, 2020)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91.md#reusing-a-pretrained-language-model-on-languages-with-limited-corpora-for-unsupervised-nmt-alexandra-emnlp-2020)

    - [æœºå™¨ç¿»è¯‘é¢„è®­ç»ƒæ¨¡å‹](https://github.com/junchaoIU/NLP-Learning-Notes/tree/main/docs/æœºå™¨ç¿»è¯‘/æœºå™¨ç¿»è¯‘é¢„è®­ç»ƒæ¨¡å‹.md)
        - [Multilingual Denoising Pre-training for Neural Machine Translation (Yinhan Liu, Transactions of the Association for Computational Linguistics, 2022)](https://github.com/junchaoIU/NLP-Learning-Notes/blob/main/docs/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.md) 


- æœªåˆ†ç±»
    - [Attention is All You Need (Vaswani, NIPS, 2017)]()

- æ¨¡å‹å‹ç¼©
    - [TinyBERT: Distilling BERT for Natural Language Understanding (Xiaoqi Jiao, EMNLP, 2020)]()

-----
## ğŸ‰ æ¬¢è¿æ‰¹è¯„æŒ‡æ­£ 
ç”±äºä¸ªäººæ°´å¹³æœ‰é™ï¼Œç¬”è®°ä¸­éš¾å…æœ‰ç¬”è¯¯ç”šè‡³æ¦‚å¿µé”™è¯¯ä¹‹å¤„ï¼Œè¯·å„ä½ä¸åèµæ•™ï¼Œåœ¨issueä¸­æå‡ºæ¥ã€‚

-----
## ğŸŒ¸ å…³äºä½œè€…
[WU, JUNCHAO](https://github.com/junchaoIU)

[ä¸ªäººå­¦æœ¯ä¸»é¡µ](https://junchaoiu.github.io/)

[ä¸ªäººåšå®¢-æ˜¥å¤©ä¸çˆ±æƒ…ã®æ¨±èŠ±ğŸŒ¸](https://www.wujunchao.top/)

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·è‡´é‚®ï¼ˆEmailï¼‰ï¼šwujunchaoIU@outlook.com