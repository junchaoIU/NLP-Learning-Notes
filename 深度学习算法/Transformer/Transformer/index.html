<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content=WU,Junchao><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.4.2, mkdocs-material-8.2.6"><title>Transformer - NLP学习笔记</title><link rel=stylesheet href=../../../assets/stylesheets/main.9d5733d3.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.e6a45f82.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=light-purple data-md-color-accent=deep-purple> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#transformer class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../../.. title=NLP学习笔记 class="md-header__button md-logo" aria-label=NLP学习笔记 data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> NLP学习笔记 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Transformer </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=light-purple data-md-color-accent=deep-purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=cyan data-md-color-accent=deep-purple aria-label="Switch to light mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=查找> <a href=javascript:void(0) class="md-search__icon md-icon" aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08z"/></svg> </a> <button type=reset class="md-search__icon md-icon" aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/junchaoIU/NLP-Learning-Notes/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> NLP-Learning-Notes </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title=NLP学习笔记 class="md-nav__button md-logo" aria-label=NLP学习笔记 data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg> </a> NLP学习笔记 </label> <div class=md-nav__source> <a href=https://github.com/junchaoIU/NLP-Learning-Notes/ title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> NLP-Learning-Notes </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> 前言 </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_2 type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2> How to Research <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="How to Research" data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> How to Research </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../How%20to%20Research/%E6%96%87%E7%8C%AE%E6%9F%A5%E8%AF%A2%E4%B8%8E%E9%98%85%E8%AF%BB/%E6%96%87%E7%8C%AE%E6%9F%A5%E8%AF%A2%E4%B8%8E%E9%98%85%E8%AF%BB/ class=md-nav__link> 文献查询与阅读 </a> </li> <li class=md-nav__item> <a href=../../../How%20to%20Research/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/ class=md-nav__link> 论文写作 </a> </li> <li class=md-nav__item> <a href=../../../How%20to%20Research/%E5%88%86%E4%BA%AB%E7%A0%94%E7%A9%B6/%E5%88%86%E4%BA%AB%E7%A0%94%E7%A9%B6/ class=md-nav__link> 分享研究 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3> 学术论文技巧 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=学术论文技巧 data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> 学术论文技巧 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E7%9B%B8%E5%85%B3/%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E5%88%86%E7%B1%BB/%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E5%88%86%E7%B1%BB/ class=md-nav__link> 学术论文分类 </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_2 type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2> 学术论文写作 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=学术论文写作 data-md-level=2> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 学术论文写作 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E7%9B%B8%E5%85%B3/%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/Cover%20Letter/Cover%20Letter/ class=md-nav__link> Cover Letter </a> </li> <li class=md-nav__item> <a href=../../../%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E7%9B%B8%E5%85%B3/%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C/Revising/Revising/ class=md-nav__link> Revising </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_4 type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4> 自然语言处理 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=自然语言处理 data-md-level=1> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> 自然语言处理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%B8%AD%E6%96%87NLP%E7%A0%94%E7%A9%B6%E4%B8%8E%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/%E4%B8%AD%E6%96%87NLP%E7%A0%94%E7%A9%B6%E4%B8%8E%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/ class=md-nav__link> 中文NLP研究与资源汇总 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/NLP%E6%A6%82%E8%BF%B0/NLP%E6%A6%82%E8%BF%B0/ class=md-nav__link> NLP概述 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF/ class=md-nav__link> 中文分词技术 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/ class=md-nav__link> 命名实体识别 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/ class=md-nav__link> 关系抽取 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8/%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8/ class=md-nav__link> 词性标注 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E5%8C%96/%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E5%8C%96/ class=md-nav__link> 文本向量化 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/ class=md-nav__link> 句法分析 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/ class=md-nav__link> 情感分析 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/ class=md-nav__link> 信息抽取 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E8%81%9A%E7%B1%BB/%E6%96%87%E6%9C%AC%E8%81%9A%E7%B1%BB/ class=md-nav__link> 文本聚类 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/ class=md-nav__link> 文本分类 </a> </li> <li class=md-nav__item> <a href=../../../%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96/ class=md-nav__link> 事件抽取 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5 type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5> 统计机器学习 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=统计机器学习 data-md-level=1> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> 统计机器学习 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/K%E8%BF%91%E9%82%BB/K%E8%BF%91%E9%82%BB/ class=md-nav__link> K近邻 </a> </li> <li class=md-nav__item> <a href=../../../%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/%E5%86%B3%E7%AD%96%E6%A0%91/ class=md-nav__link> 决策树 </a> </li> <li class=md-nav__item> <a href=../../../%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/ class=md-nav__link> 神经网络 </a> </li> <li class=md-nav__item> <a href=../../../%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/ class=md-nav__link> 降维与度量学习 </a> </li> <li class=md-nav__item> <a href=../../../%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/ class=md-nav__link> 无监督学习概论 </a> </li> <li class=md-nav__item> <a href=../../../%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/PageRank%E7%AE%97%E6%B3%95/PageRank%E7%AE%97%E6%B3%95/ class=md-nav__link> PageRank算法 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_6 type=checkbox id=__nav_6 checked> <label class=md-nav__link for=__nav_6> 深度学习算法 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=深度学习算法 data-md-level=1> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> 深度学习算法 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../BERT/BERT/ class=md-nav__link> BERT </a> </li> <li class=md-nav__item> <a href=../../LSTM/LSTM/ class=md-nav__link> LSTM </a> </li> <li class=md-nav__item> <a href=../../RNNs/RNNs/ class=md-nav__link> RNNs </a> </li> <li class=md-nav__item> <a href=../../CNN/CNN/ class=md-nav__link> CNN </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Transformer <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Transformer </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-transformer class=md-nav__link> 1. Transformer架构 </a> <nav class=md-nav aria-label="1. Transformer架构"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#11 class=md-nav__link> 1.1 总体框架 </a> </li> <li class=md-nav__item> <a href=#12-encoder class=md-nav__link> 1.2 Encoder </a> </li> <li class=md-nav__item> <a href=#13-decoder class=md-nav__link> 1.3 Decoder </a> </li> <li class=md-nav__item> <a href=#14-attention class=md-nav__link> 1.4 Attention </a> </li> <li class=md-nav__item> <a href=#15-self-attention class=md-nav__link> 1.5 Self-Attention </a> </li> <li class=md-nav__item> <a href=#16-context-attention class=md-nav__link> 1.6 Context-Attention </a> </li> <li class=md-nav__item> <a href=#17-scaled-dot-product-attention class=md-nav__link> 1.7 Scaled Dot-Product Attention </a> </li> <li class=md-nav__item> <a href=#18-multi-head-attention class=md-nav__link> 1.8 Multi-head attention </a> </li> <li class=md-nav__item> <a href=#19-layer-normalization class=md-nav__link> 1.9 Layer normalization </a> </li> <li class=md-nav__item> <a href=#110-mask class=md-nav__link> 1.10 Mask </a> <nav class=md-nav aria-label="1.10 Mask"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1101-padding-mask class=md-nav__link> 1.10.1 Padding Mask </a> </li> <li class=md-nav__item> <a href=#1102-sequence-mask class=md-nav__link> 1.10.2 Sequence mask </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#111-positional-embedding class=md-nav__link> 1.11 Positional Embedding </a> </li> <li class=md-nav__item> <a href=#112-position-wise-feed-forward-network class=md-nav__link> 1.12 Position-wise Feed-Forward network </a> </li> <li class=md-nav__item> <a href=#_1 class=md-nav__link> 参考 </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_7 type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7> 知识图谱技术 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=知识图谱技术 data-md-level=1> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> 知识图谱技术 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%A6%82%E8%BF%B0/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%A6%82%E8%BF%B0/ class=md-nav__link> 知识图谱概述 </a> </li> <li class=md-nav__item> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA/ class=md-nav__link> 知识表示 </a> </li> <li class=md-nav__item> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E7%9F%A5%E8%AF%86%E5%BB%BA%E6%A8%A1/%E7%9F%A5%E8%AF%86%E5%BB%BA%E6%A8%A1/ class=md-nav__link> 知识建模 </a> </li> <li class=md-nav__item> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96/%E7%9F%A5%E8%AF%86%E6%8A%BD%E5%8F%96/ class=md-nav__link> 知识抽取 </a> </li> <li class=md-nav__item> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E7%9F%A5%E8%AF%86%E8%9E%8D%E5%90%88/%E7%9F%A5%E8%AF%86%E8%9E%8D%E5%90%88/ class=md-nav__link> 知识融合 </a> </li> <li class=md-nav__item> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0/ class=md-nav__link> 知识表示学习 </a> </li> <li class=md-nav__item> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E7%9F%A5%E8%AF%86%E5%AD%98%E5%82%A8/%E7%9F%A5%E8%AF%86%E5%AD%98%E5%82%A8/ class=md-nav__link> 知识存储 </a> </li> <li class=md-nav__item> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%86/%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%86/ class=md-nav__link> 知识推理 </a> </li> <li class=md-nav__item> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%A6%82%E8%BF%B0/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%A6%82%E8%BF%B0/ class=md-nav__link> 多模态知识图谱概述 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_8 type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8> 机器翻译 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=机器翻译 data-md-level=1> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> 机器翻译 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E6%A6%82%E8%BF%B0/ class=md-nav__link> 机器翻译概述 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E9%9D%9E%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/ class=md-nav__link> 非自回归模型机器翻译 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/RNN%E7%A5%9E%E7%BB%8F%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/ class=md-nav__link> RNN神经机器翻译 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/CNN%E7%A5%9E%E7%BB%8F%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/ class=md-nav__link> CNN神经机器翻译 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/Transformer%E7%A5%9E%E7%BB%8F%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/ class=md-nav__link> Transformer神经机器翻译 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%97%A0%E7%9B%91%E7%9D%A3%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/ class=md-nav__link> 无监督机器翻译 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E5%A4%9A%E8%AF%AD%E8%A8%80%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/ class=md-nav__link> 多语言机器翻译 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/ class=md-nav__link> 多模态机器翻译 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E7%AF%87%E7%AB%A0%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/ class=md-nav__link> 篇章机器翻译 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E9%A2%86%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94/ class=md-nav__link> 领域自适应 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%A2%9E%E5%BC%BA%E7%9A%84%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/ class=md-nav__link> 知识图谱增强的机器翻译 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/BPE%E7%BC%96%E7%A0%81/ class=md-nav__link> BPE编码 </a> </li> <li class=md-nav__item> <a href=../../../%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/ class=md-nav__link> 机器翻译预训练模型 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_9 type=checkbox id=__nav_9> <label class=md-nav__link for=__nav_9> 立场检测研究 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=立场检测研究 data-md-level=1> <label class=md-nav__title for=__nav_9> <span class="md-nav__icon md-icon"></span> 立场检测研究 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E7%AB%8B%E5%9C%BA%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/%E7%AB%8B%E5%9C%BA%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/ class=md-nav__link> 立场检测笔记 </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_9_2 type=checkbox id=__nav_9_2> <label class=md-nav__link for=__nav_9_2> 数据集 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=数据集 data-md-level=2> <label class=md-nav__title for=__nav_9_2> <span class="md-nav__icon md-icon"></span> 数据集 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E7%AB%8B%E5%9C%BA%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/NLPCC2016-Task4/NLPCC2016-Task4/ class=md-nav__link> NLPCC2016-Task4 </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_10 type=checkbox id=__nav_10> <label class=md-nav__link for=__nav_10> 经验笔记 <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=经验笔记 data-md-level=1> <label class=md-nav__title for=__nav_10> <span class="md-nav__icon md-icon"></span> 经验笔记 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E7%BB%8F%E9%AA%8C%E4%B9%8B%E8%B0%88/Pytorch%E5%AE%89%E8%A3%85/ class=md-nav__link> PyTorch安装 </a> </li> <li class=md-nav__item> <a href=../../../%E7%BB%8F%E9%AA%8C%E4%B9%8B%E8%B0%88/fairseq%E7%AC%94%E8%AE%B0/ class=md-nav__link> Fairseq框架 </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-transformer class=md-nav__link> 1. Transformer架构 </a> <nav class=md-nav aria-label="1. Transformer架构"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#11 class=md-nav__link> 1.1 总体框架 </a> </li> <li class=md-nav__item> <a href=#12-encoder class=md-nav__link> 1.2 Encoder </a> </li> <li class=md-nav__item> <a href=#13-decoder class=md-nav__link> 1.3 Decoder </a> </li> <li class=md-nav__item> <a href=#14-attention class=md-nav__link> 1.4 Attention </a> </li> <li class=md-nav__item> <a href=#15-self-attention class=md-nav__link> 1.5 Self-Attention </a> </li> <li class=md-nav__item> <a href=#16-context-attention class=md-nav__link> 1.6 Context-Attention </a> </li> <li class=md-nav__item> <a href=#17-scaled-dot-product-attention class=md-nav__link> 1.7 Scaled Dot-Product Attention </a> </li> <li class=md-nav__item> <a href=#18-multi-head-attention class=md-nav__link> 1.8 Multi-head attention </a> </li> <li class=md-nav__item> <a href=#19-layer-normalization class=md-nav__link> 1.9 Layer normalization </a> </li> <li class=md-nav__item> <a href=#110-mask class=md-nav__link> 1.10 Mask </a> <nav class=md-nav aria-label="1.10 Mask"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1101-padding-mask class=md-nav__link> 1.10.1 Padding Mask </a> </li> <li class=md-nav__item> <a href=#1102-sequence-mask class=md-nav__link> 1.10.2 Sequence mask </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#111-positional-embedding class=md-nav__link> 1.11 Positional Embedding </a> </li> <li class=md-nav__item> <a href=#112-position-wise-feed-forward-network class=md-nav__link> 1.12 Position-wise Feed-Forward network </a> </li> <li class=md-nav__item> <a href=#_1 class=md-nav__link> 参考 </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/junchaoIU/NLP-Learning-Notes/edit/master/docs/深度学习算法/Transformer/Transformer.md title=编辑此页 class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1 id=transformer>Transformer</h1> <h2 id=1-transformer>1. Transformer架构</h2> <h3 id=11>1.1 总体框架</h3> <p><img alt src=../image/image_0ModhMWYYI.png></p> <p>上图所示为Transformer 的架构。和经典的 seq2seq 模型一样，Transformer 模型中也采用了 encoer-decoder 架构。上图的左半边用 <strong>NX</strong> 框出来的，就代表一层 encoder，其中论文里面的 encoder 一共有6层这样的结构。上图的右半边用 <strong>NX</strong> 框出来的，则代表一层 decoder，同样也有6层。</p> <p>定义输入序列首先经过 word embedding，再和 positional encoding 相加后，输入到 encoder 中。输出序列经过的处理和输入序列一样，然后输入到 decoder。</p> <p>最后，decoder 的输出经过一个线性层，再接 Softmax。</p> <p>于上便是 Transformer 的整体框架，下面先来介绍 encoder 和 decoder。</p> <h3 id=12-encoder>1.2 Encoder</h3> <p>encoder由 6 层相同的层组成，每一层分别由两部分组成：</p> <ul> <li> <p>第一部分是 multi-head self-attention</p> </li> <li> <p>第二部分是 position-wise feed-forward network，是一个全连接层</p> </li> </ul> <p>两个部分，都有一个残差连接(residual connection)，然后接着一个 Layer Normalization。</p> <h3 id=13-decoder>1.3 Decoder</h3> <p>和 encoder 类似，decoder 也是由6个相同的层组成，每一个层包括以下3个部分:</p> <ul> <li> <p>第一个部分是 multi-head self-attention mechanism</p> </li> <li> <p>第二部分是 multi-head context-attention mechanism</p> </li> <li> <p>第三部分是一个 position-wise feed-forward network</p> </li> </ul> <p>和 encoder 一样，上面三个部分的每一个部分，都有一个残差连接，后接一个 <strong>Layer Normalization</strong>。</p> <p>decoder 和 encoder 不同的地方在 multi-head context-attention mechanism</p> <h3 id=14-attention>1.4 Attention</h3> <p>Attention 如果用一句话来描述，那就是 encoder 层的输出经过加权平均后再输入到 decoder 层中。它主要应用在 seq2seq 模型中，这个加权可以用矩阵来表示，也叫 Attention 矩阵。它表示对于某个时刻的输出 y，它在输入 x 上各个部分的注意力。这个注意力就是我们刚才说到的加权。</p> <p>Attention 又分为很多种，其中两种比较典型的有加性 Attention 和乘性 Attention。加性 Attention 对于输入的隐状态h_t和输出的隐状态 s_t直接做 concat 操作，得到[s_t; h_t]，乘性 Attention 则是对输入和输出做 dot 操作。</p> <p>Transformer使用的是乘性 Attention.</p> <h3 id=15-self-attention>1.5 Self-Attention</h3> <p>上面我们说attention机制的时候，都会说到两个隐状态，分别是h_i和s_t。前者是输入序列第 i个位置产生的隐状态，后者是输出序列在第 t 个位置产生的隐状态。所谓 self-attention 实际上就是，输出序列就是输入序列。因而自己计算自己的 attention 得分。</p> <h3 id=16-context-attention>1.6 Context-Attention</h3> <p>context-attention 是 encoder 和 decoder 之间的 attention，是两个不同序列之间的attention，与来源于自身的 self-attention 相区别。</p> <p>不管是哪种 attention，我们在计算 attention 权重的时候，可以选择很多方式，常用的方法有</p> <ul> <li> <p>additive attention</p> </li> <li> <p>local-base</p> </li> <li> <p>general</p> </li> <li> <p>dot-product</p> </li> <li> <p>scaled dot-product</p> </li> </ul> <p>Transformer模型采用的是最后一种：scaled dot-product attention。</p> <h3 id=17-scaled-dot-product-attention>1.7 Scaled Dot-Product Attention</h3> <p><img alt src=../image/image_QZuZTgNAnF.png></p> <p>通过 query 和 key 的相似性程度来确定 value 的权重分布。论文中的公式长下面这个样子：</p> <p>K、Q、V 分别代表什么：</p> <ul> <li> <p>在 encoder 的 self-attention 中，Q、K、V 都来自同一个地方，它们是上一层 encoder 的输出。对于第一层 encoder，它们就是 word embedding 和 positional encoding 相加得到的输入。</p> </li> <li> <p>在 decoder 的 self-attention 中，Q、K、V 也是自于同一个地方，它们是上一层 decoder 的输出。对于第一层 decoder，同样也是 word embedding 和 positional encoding 相加得到的输入。但是对于 decoder，我们不希望它能获得下一个 time step (即将来的信息，不想让他看到它要预测的信息)，因此我们需要进行 sequence masking。</p> </li> <li> <p>在 encoder-decoder attention 中，Q 来自于 decoder 的上一层的输出，K 和 V 来自于 encoder 的输出，K 和 V 是一样的。</p> </li> <li> <p>Q、K、V 的维度都是一样的，分别用d_Q，d_K和d_V来表示</p> </li> <li> <p>Google 论文的主要贡献之一是它表明了内部注意力在机器翻译 (甚至是一般的Seq2Seq任务）的序列编码上是相当重要的，而之前关于 Seq2Seq 的研究基本都只是把注意力机制用在解码端。</p> </li> </ul> <h3 id=18-multi-head-attention>1.8 Multi-head attention</h3> <p>理解了 Scaled dot-product attention，Multi-head attention 也很容易理解啦。论文提到，他们发现将 Q、K、V 通过一个线性映射之后，分成 h 份，对每一份进行 scaled dot-product attention 效果更好。然后，把各个部分的结果合并起来，再次经过线性映射，得到最终的输出。这就是所谓的 multi-head attention。上面的超参数 h 就是 heads 的数量。论文默认是 8。</p> <p>multi-head attention 的结构图如下所示。</p> <p><img alt src=../image/image_GQCk7UwasE.png></p> <p>值得注意的是，上面所说的分成 h 份是在d_Q、d_K和d_V的维度上进行切分。因此进入到scaled dot-product attention 的d_K实际上等于未进入之前的D_K/h</p> <p>Multi-head attention 的公式如下：</p> <p><img alt src=../image/image_bpq1u0uDkf.png></p> <p>其中，</p> <p><img alt src=../image/image_b99Wy380jS.png></p> <p>在论文里面，d_model = 512，h = 8，所以在 scaled dot-product attention 里面的</p> <p><img alt src=../image/image_k5_g1suywe.png></p> <p>可以看出，所谓 Multi-Head，就是只多做几次同样的事情，同时参数不共享，然后把结果拼接。</p> <h3 id=19-layer-normalization>1.9 Layer normalization</h3> <blockquote> <p>Normalization 有很多种，但是它们都有一个共同的目的，那就是把输入转化成均值为 0 方差为 1 的数据。我们在把数据送入激活函数之前进行 normalization（归一化），因为我们不希望输入数据落在激活函数的饱和区。</p> </blockquote> <p>说到 normalization，那就肯定得提到 Batch Normalization。</p> <p>BN 的主要思想就是：在每一层的每一批数据上进行归一化。我们可能会对输入数据进行归一化，但是经过该网络层的作用后，我们的数据已经不再是归一化的了。随着这种情况的发展，数据的偏差越来越大，我的反向传播需要考虑到这些大的偏差，这就迫使我们只能使用较小的学习率来防止梯度消失或者梯度爆炸。</p> <h3 id=110-mask>1.10 Mask</h3> <p>mask 表示掩码，它对某些值进行掩盖，使其在参数更新时不产生效果。Transformer 模型里面涉及两种 mask，分别是 padding mask 和 sequence mask。</p> <p>其中，padding mask 在所有的 scaled dot-product attention 里面都需要用到，而 sequence mask 只有在 decoder 的 self-attention 里面用到。</p> <h4 id=1101-padding-mask>1.10.1 Padding Mask</h4> <p>什么是 padding mask 呢？因为每个批次输入序列长度是不一样的也就是说，我们要对输入序列进行对齐。具体来说，就是给在较短的序列后面填充 0。因为这些填充的位置，其实是没什么意义的，所以我们的 attention 机制不应该把注意力放在这些位置上，所以我们需要进行一些处理。</p> <p>具体的做法是，把这些位置的值加上一个非常大的负数(负无穷)，这样的话，经过 softmax，这些位置的概率就会接近0！</p> <p>而我们的 padding mask 实际上是一个张量，每个值都是一个 Boolean，值为 false 的地方就是我们要进行处理的地方。</p> <h4 id=1102-sequence-mask>1.10.2 Sequence mask</h4> <p>sequence mask 是为了使得 decoder 不能看见未来的信息。也就是对于一个序列，在 time_step 为 t 的时刻，我们的解码输出应该只能依赖于 t 时刻之前的输出，而不能依赖 t 之后的输出。因此我们需要想一个办法，把 t 之后的信息给隐藏起来。</p> <p>那么具体怎么做呢？也很简单：<strong>产生一个上三角矩阵，上三角的值全为 1，下三角的值</strong><strong>全为</strong><strong>0，对角线也是 0</strong>。把这个矩阵作用在每一个序列上，就可以达到我们的目的啦。</p> <ul> <li> <p>对于 decoder 的 self-attention，里面使用到的 scaled dot-product attention，同时需要padding mask 和 sequence mask 作为 attn_mask，具体实现就是两个 mask 相加作为attn_mask。</p> </li> <li> <p>其他情况，attn_mask 一律等于 padding mask。</p> </li> </ul> <h3 id=111-positional-embedding>1.11 Positional Embedding</h3> <p>现在的 Transformer 架构还没有提取序列顺序的信息，这个信息对于序列而言非常重要，如果缺失了这个信息，可能我们的结果就是：所有词语都对了，但是无法组成有意义的语句。</p> <p>为了解决这个问题。论文使用了 Positional Embedding：对序列中的词语出现的位置进行编码。</p> <p>在实现的时候使用正余弦函数。公式如下：</p> <p><img alt src=../image/image_LLc71hoMpQ.png></p> <p>其中，pos 是指词语在序列中的位置。可以看出，在<strong>偶数位置，使用正弦编码，在奇数位置，使用余弦编码</strong>。</p> <p>从编码公式中可以看出，给定词语的 pos，我们可以把它编码成一个d_model的向量。也就是说，位置编码的每一个维度对应正弦曲线，波长构成了从2Π到10000*2Π的等比数列。</p> <p>上面的位置编码是<strong>绝对位置编码</strong>。但是词语的<strong>相对位置</strong>也非常重要。这就是为什么要使用三角函数的原因！</p> <h3 id=112-position-wise-feed-forward-network>1.12 Position-wise Feed-Forward network</h3> <p>这是一个全连接网络，包含两个线性变换和一个非线性函数(实际上就是 ReLU)。公式如下</p> <p><img alt src=../image/image_aE4c6kEknU.png></p> <p>这个线性变换在不同的位置都表现地一样，并且在不同的层之间使用不同的参数。</p> <h3 id=_1>参考</h3> <p><a href=https://arxiv.org/pdf/1706.03762.pdf title=https://arxiv.org/pdf/1706.03762.pdf>https://arxiv.org/pdf/1706.03762.pdf</a></p> <hr> <div class=md-source-file> <small> 最后更新: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">January 18, 2023</span> </small> </div> </article> </div> </div> <a href=# class="md-top md-icon" data-md-component=top data-md-state=hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg> 回到页面顶部 </a> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=页脚> <a href=../../CNN/CNN/ class="md-footer__link md-footer__link--prev" aria-label="上一页: CNN" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> 上一页 </span> CNN </div> </div> </a> <a href=../../../%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8A%80%E6%9C%AF/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%A6%82%E8%BF%B0/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%A6%82%E8%BF%B0/ class="md-footer__link md-footer__link--next" aria-label="下一页: 知识图谱概述" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> 下一页 </span> 知识图谱概述 </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2022-present <a href=https://github.com/junchaoIU target=_blank rel="noopener noreferrer">WU,Junchao</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/junchaoIU/NLP-Learning-Notes/ target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["header.autohide", "navigation.tracking", "navigation.top", "search.highlight", "search.share", "search.suggest", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.5e67fbfe.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../../assets/javascripts/bundle.e87a5f81.min.js></script> </body> </html>